# DATA STRUCTURES AND ALGORITHM

Steping into DSA Lets talk about what is DSA and why wee need that

## üå± What is Data Structure?

A data structure is a way to organize and store data in a computer so that we can use it efficiently.

üîß Examples:
üì¶ Array: A list of items stored next to each other (e.g., [10, 20, 30]).

üìö Stack: Think of a pile of books ‚Äî you can only take the top one first (LIFO - Last In First Out).

üé´ Queue: Like people in a line ‚Äî first come, first serve (FIFO - First In First Out).

üå≥ Tree: A structure like your family tree or folder structure.

üîó Linked List: A chain of items connected one by one.

üó∫Ô∏è Hash Table: Like a dictionary where you look up value using a key.

## ü§ñ What is an Algorithm?

An algorithm is a step-by-step set of instructions to solve a problem or perform a task.

üß† Example:
Imagine making tea:

Boil water

Add tea powder

Add sugar

Add milk

Strain and serve

This is an algorithm!

In coding:

Sorting numbers from small to big is done using sorting algorithms (e.g., Bubble Sort, Merge Sort).

Finding something in a list uses searching algorithms (e.g., Binary Search).

### ü§î Why Do We Need Data Structures & Algorithms (DSA)?

‚úÖ 1. Efficiency
Writing code is easy, but writing fast and efficient code is the key.

DSA helps us use memory and time wisely.

‚úÖ 2. Problem Solving
DSA teaches you how to break down problems and solve them logically.

‚úÖ 3. Job Interviews
All top tech companies like Google, Amazon, TCS, Infosys, etc., ask DSA questions in interviews.

‚úÖ 4. Better Projects
If your app, game, or website deals with lots of data, you need the right data structure to manage it.

### üéØ Simple Analogy

üëú Think of a data structure like a bag you use to carry things (data).
üö∂‚Äç‚ôÇÔ∏è An algorithm is the way you pack and take out items from the bag.

If you pack smart (use the right data structure) and work smart (use a good algorithm), you‚Äôll solve problems faster and better.

---

## üì¶ Memory Allocation & üï≥Ô∏è Memory Leak

Memory allocation refers to the process of assigning and deallocating memory in a computer system.
There are various memory allocation techniques, including stack-based allocation and dynamic allocation.

#### üì¶ Why is Memory Allocation Important?

- üíæ Our computer has **limited RAM**.
- üß† We need to **store and manage data properly**.
- ‚ö° Efficient memory allocation:
  - Prevents **wastage of memory**
  - Makes programs **faster** and more **stable**

#### üï≥Ô∏è What is a Memory Leak?

A **Memory Leak** happens when your program **allocates memory**, but **doesn‚Äôt release (free)** it when it‚Äôs no longer needed.

#### üí• Result:

- üö® Your program keeps **using more memory** over time.
- üê¢ It can **slow down** or even **crash** the system if RAM runs out!

#### Stack-Based Allocation

Stack-based allocation is a common method used by programming languages to manage memory. It involves utilizing a region of memory called the stack, which automatically allocates and deallocates memory for variables within a limited scope. This approach is fast and efficient, making it suitable for managing small and short-lived data.

#### Dynamic Allocation

Dynamic allocation, on the other hand, allows for more flexible memory management. It involves allocating memory from a region called the heap, which is larger and can accommodate more significant amounts of data. Dynamic allocation is particularly useful when dealing with data structures that require varying amounts of memory or when handling large datasets.

#### Memory Leaks: Causes and Consequences

Memory leaks are a common issue in software development that can have detrimental effects on the performance and stability of an application. A memory leak occurs when allocated memory is not properly deallocated, resulting in memory being reserved but no longer accessible for other processes. Over time, memory leaks can lead to increased memory consumption and a gradual degradation of system performance.

## üìò Complexity Analysis

**Complexity Analysis** is a method to evaluate how the performance of an algorithm or data structure scales with the size of the input. It primarily involves:

- **Time Complexity**: Measures the amount of time an algorithm takes to complete as a function of the input size.
- **Space Complexity**: Measures the amount of memory an algorithm uses relative to the input size.

These complexities are often expressed using **Big O notation**, which provides an upper bound on the growth rate of an algorithm's resource consumption.

### üßÆ Common Time Complexities in Big O Notation

| Big O Notation | Name              | Description                                                         |
| -------------- | ----------------- | ------------------------------------------------------------------- |
| O(1)           | Constant Time     | Execution time doesn't change with input size.                      |
| O(log n)       | Logarithmic Time  | Execution time increases logarithmically with input size.           |
| O(n)           | Linear Time       | Execution time increases linearly with input size.                  |
| O(n log n)     | Linearithmic Time | Execution time increases in proportion to n log n.                  |
| O(n¬≤)          | Quadratic Time    | Execution time increases proportionally to the square of the input. |
| O(2‚Åø)          | Exponential Time  | Execution time doubles with each additional input element.          |
| O(n!)          | Factorial Time    | Execution time increases factorially with input size.               |

### üóÉÔ∏è Time and Space Complexities of Common Data Structures

### 1. Array

| Operation | Time Complexity |
| --------- | --------------- |
| Access    | O(1)            |
| Search    | O(n)            |
| Insertion | O(n)            |
| Deletion  | O(n)            |

- **Space Complexity**: O(n)

---

### 2. Stack

| Operation | Time Complexity |
| --------- | --------------- |
| Push      | O(1)            |
| Pop       | O(1)            |
| Peek      | O(1)            |

- **Space Complexity**: O(n)

---

### 3. Queue

| Operation | Time Complexity |
| --------- | --------------- |
| Enqueue   | O(1)            |
| Dequeue   | O(1)            |
| Peek      | O(1)            |

- **Space Complexity**: O(n)

---

### 4. Singly Linked List

| Operation | Time Complexity |
| --------- | --------------- |
| Access    | O(n)            |
| Search    | O(n)            |
| Insertion | O(1)            |
| Deletion  | O(1)            |

- **Space Complexity**: O(n)

---

### 5. Doubly Linked List

| Operation | Time Complexity |
| --------- | --------------- |
| Access    | O(n)            |
| Search    | O(n)            |
| Insertion | O(1)            |
| Deletion  | O(1)            |

- **Space Complexity**: O(n)

---

### 6. Hash Table

| Operation | Average Time | Worst Case Time |
| --------- | ------------ | --------------- |
| Search    | O(1)         | O(n)            |
| Insertion | O(1)         | O(n)            |
| Deletion  | O(1)         | O(n)            |

- **Space Complexity**: O(n)

---

### 7. Binary Search Tree (BST)

| Operation | Average Time | Worst Case Time |
| --------- | ------------ | --------------- |
| Search    | O(log n)     | O(n)            |
| Insertion | O(log n)     | O(n)            |
| Deletion  | O(log n)     | O(n)            |

- **Space Complexity**: O(n)

---

### 8. Balanced BST (e.g., AVL, Red-Black Tree)

| Operation | Time Complexity |
| --------- | --------------- |
| Search    | O(log n)        |
| Insertion | O(log n)        |
| Deletion  | O(log n)        |

- **Space Complexity**: O(n)

---

### 9. Heap

| Operation      | Time Complexity |
| -------------- | --------------- |
| Insert         | O(log n)        |
| Delete Min/Max | O(log n)        |
| Peek Min/Max   | O(1)            |

- **Space Complexity**: O(n)

---

### 10. Trie (Prefix Tree)

| Operation | Time Complexity |
| --------- | --------------- |
| Search    | O(m)            |
| Insertion | O(m)            |
| Deletion  | O(m)            |

- **Space Complexity**: O(n \* m)

> Where **n** is the number of keys and **m** is the length of the key.

## Stack vs Heap Memory

### üì¶ 1. Stack Memory ‚Äì Fast and Organized

‚úÖ Used for:

- Function calls
- Local variables (like numbers, booleans, temporary values)
- Keeps track of "who called whom" in a program

üß± Structure:

- LIFO (Last In, First Out) ‚Äî like a stack of plates üçΩÔ∏è
- Memory is managed automatically ‚Äî when a function ends, its stack memory is cleared.

‚ö° Example:

```js
function add(a, b) {
  let result = a + b; // result is stored in stack
  return result;
}
```

üîÅ What happens:
When add() is called, a stack frame is created for it.

Inside it, a, b, and result are stored.

After return, memory is cleared.

### üß≥ 2. Heap Memory ‚Äì Flexible and Dynamic

‚úÖ Used for:
Objects, arrays, or anything created dynamically (new Object(), or in JS: {}, [])

Memory that needs to persist beyond function calls

üß± Structure:
No order like LIFO

Memory is allocated and freed manually (in C/C++) or via garbage collection (in JS, Java, etc.)

‚ö° Example in JavaScript:

```js
function createUser() {
  let user = { name: 'Ebi' }; // stored in heap
  return user;
}
```

üîÅ What happens:
The { name: "Ebi" } object is stored in the heap.

- The user variable in the stack holds a reference (a pointer) to the heap.

---

---

### üß† What is XOR?

**XOR** stands for **Exclusive OR**. It is a bitwise operator that compares two bits and returns:

- `1` if the bits are **different**
- `0` if the bits are **same**

#### XOR Truth Table:

| A   | B   | A ‚äï B |
| --- | --- | ----- |
| 0   | 0   | 0     |
| 0   | 1   | 1     |
| 1   | 0   | 1     |
| 1   | 1   | 0     |

#### ‚úÖ XOR Properties (Very Useful in Coding)

| Property               | Meaning                          |
| ---------------------- | -------------------------------- |
| `a ^ 0 = a`            | XOR with 0 gives the same number |
| `a ^ a = 0`            | XOR with itself gives 0          |
| `a ^ b ^ a = b`        | Same values cancel out           |
| XOR is **commutative** | `a ^ b = b ^ a`                  |
| XOR is **associative** | `(a ^ b) ^ c = a ^ (b ^ c)`      |

---

---

## TREE DATA STRUCTURES üå≥

What is Tree?

A tree in DSA (Data Structures and Algorithms) is a way to organize data. It looks like an upside-down tree with a root at the top and branches spreading out. Each point on the tree is called a node, and the lines connecting them are called edges. The top node is the root, and nodes with no children are called leaves.

### Types of Trees in Data Structure

#### 1) Binary Tree

-Time Complexity(o(n))

A binary tree is a tree data structure where each node has at most two children, referred to as the left child and the right child.

TYPES OF BINARY TREE

-Full binary Tree

A full binary tree is a tree where every node has either 0 or 2 children.

-Complete Binary Tree

A complete binary tree is a tree where all levels are fully filled except possibly the last level, which is filled from left to right.

-Perfect Binary Tree

A perfect binary tree is a tree where all internal nodes have exactly two children and all leaf nodes are at the same level.

-Balanced Binary Tree

A balanced binary tree is a tree where the height of the left and right subtrees of any node differ by at most one.

#### 2) Binary Search Tree

A binary search tree is a binary tree where each node has a value, and the left child's value is less than the parent's value, while the right child's value is greater than the parent's value.

#### 3) AVL Tree

An AVL tree is a self-balancing binary search tree where the difference in heights between the left and right subtrees of any node is at most one.

#### 4) Red Black Tree

A red-black tree is a self-balancing binary search tree where each node contains an extra bit for color (red or black) to ensure the tree remains balanced.

#### 5) Heap

A heap is a special tree-based data structure that satisfies the heap property: in a max-heap, each parent node is greater than or equal to its children; in a min-heap, each parent node is less than or equal to its children.

#### 6) B-Tree

A B-tree is a self-balancing search tree in which nodes can have multiple children. It is commonly used in databases and file systems.

#### 7) Segment Tree

A segment tree is a binary tree used for storing intervals or segments. It allows querying which segments contain a given point.

---

## GRAPH DATA STRUCTURES

A graph in data structure is a way to show how things are connected. Think of it like a map of roads connecting different cities. In a graph, the cities are called "nodes" or "vertices," and the roads are called "edges." Graphs help us understand how things are linked together and how they interact.

#### TYPES OF GRAPH

- Directed graph

In a directed graph, edges have a direction, meaning they go from one node to another in a specific way.

- Undirected graph

In an undirected graph, edges do not have a direction. They simply connect two nodes without any particular order.

- Weighted Graph

In a weighted graph, edges have weights or costs associated with them. These weights can represent distances, costs, or any other metric.

- Unweighted graph

In an unweighted graph, all edges have the same weight, typically considered as 1.

- Cyclic graph

A cyclic graph contains at least one cycle, meaning you can start at a node and follow a path that leads back to the same node

- Acyclic graph

An acyclic graph does not contain any cycles.

- Connected graph

A connected graph has a path between every pair of nodes.

- Disconnected graph

A disconnected graph has at least one pair of nodes with no path between them.

#### Representations of Graph Data Structure

- Adjacency Matrix

An adjacency matrix is a 2D array used to represent a graph. Each cell in the matrix indicates whether an edge exists between a pair of vertices. If an edge exists, the cell contains a value (typically 1 for unweighted graphs or the weight of the edge for weighted graphs); otherwise, it contains 0.

- Adjacency List

An adjacency list is an array of lists. The array's indices represent the vertices, and each element in the array is a list of vertices adjacent to the vertex at that index.
